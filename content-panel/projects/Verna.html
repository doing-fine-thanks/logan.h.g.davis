<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Verna</title>
    <link href="https://fonts.googleapis.com/css?family=Inconsolata" rel="stylesheet">

    <style>
        body {
            padding: 5%;
            margin-right: 15%;
        }

        h1 {
            font-family: 'Inconsolata';
        }

        h2 {
            font-family: 'Inconsolata';
        }

        h3 {
            font-family: 'Inconsolata';
        }

        h4 {
            font-family: 'Inconsolata';
        }

        img {
            width: 100%;
            height: auto;
            margin-left: auto;
            margin-right: auto;
            display: block;
        }
    </style>
</head>
<body>
<h1> Statement: </h1>
<p>
    <i>Verna Gray</i> is a documentary both of my family maternal family history and of my grandmother's story telling.
    There have been prior attempts to catalog the story of how the family ended up in Jutland, New Jersey,
    but each attempt failed because one simple fact: a lot of people were doing a lot of things, all at
    the same time.
</p>
<p>
    My grandmother has been the wrangler of these narrative threads. Her stories weave in between decades,
    countries, and center figures. Her weaving of these events makes it evident that no codex could
    convey the tapestry of lives that landed my family were they are.  This project builds on the
    structure-as-tangent principles I used in projects like <a href="Release/Release.html" target="_parent"><i>Release</i></a>.
    Its tangents are crafted so any ending is a valid one, so this non-linearity is exploration, not
    failure (like it is in other interactive video projects such as Netflix's <a href="https://en.wikipedia.org/wiki/Black_Mirror:_Bandersnatch" target="_parent"></a><i>Bandersnatch</i></a>).
</p>
<p>
    The structure, which will be talked about in greater depth in the technical section, takes inspiration
    from Italo Calvino's <i>Invisible Cities</i>. Though rather than a conversation that moves either by
    conversational-order or by city, the traversal of this video moves conversational-order or by semantic
    subject (Sam Barlow's <i>Immortality</i>).
</p>

<h2>Process Discussion:</h2>
<h4>Intro:</h4>
<p>
    In the Fall of 2021 I say down with my grandmother and recorder her going through the family
    history over the course of 4 days. The end result was 8 hours of video that darted between people,
    places, decades, and tense. The only way I could think to properly archive all the stories
    she during our conversations was to organize it in a tree of tangents: the way it was told.
</p>
<h4>The Bandwidth Issue and Clip Organization:</h4>
<p>
    The initial editing pass was just cutting out b-roll, silent periods, and sections that were specifically
    requested to be removed. This resulted in about 6 hours of usable video. During that initial cut editing
    process, I was developing a way to show all of this footage in a tree structure. Having done  <a href="Release/Release.html" target="_parent"><i>Release</i></a>,
    I know the impact the technical constraints of a projects' presentation affects it's editing process. It
    was a notable burden with just text, so I assumed that friction between editing and distribution would
    only be heightened with video.
</p>
<p>
    The constraints of I targeted when initially exploring implementations was this:
    <ul>
        <li>Only having the user download the video they will watch.</li>
        <li>Minimizing duplication of watched footage. ~6 hours of video streamed is non-functional on a low bandwidth connection.</li>
        <li>Minimal buffering between transitions.</li>
    </ul>
</p>
<p>
    5 hours of video, even compressed for the web, is prohibitively large. For reference, the final 720p exports
    of the footage still takes ~27 gigabytes of storage. It's a lot to shove over the wire.
</p>
<p>
    Initially I thought about having one long video that would jump to the timestamp appropriate, but it caused
    extremely long buffering times to load in the new section of video. There are <a href="https://www.w3.org/TR/media-frags/" target="_parent"> media fragments</a>
    but you can't load multiple fragments in a single video (it just loads a single fragment at a time), so there
    was no tangible benefit from it for this use-case.
</p>
<p>
    Another option could have been having two videos that would swap with one being the actively playing video and
    the other being a buffer that would load the next section and then swap in once the transition took place. Again
    this runs into the issue of controlling loading and bandwidth. You can't alter media fragments because that causes
    the <a href="https://stackoverflow.com/questions/53948385/using-media-fragments-and-preventing-the-browser-from-reloading-the-targeted-htm" target="_parent"> video element to reload</a>.
    Between the metadata exchange and the reindexing into the file, the management of fragment boundaries seems like too
    much overhead for the payoff. Without some boundary for the buffering-non-active video, it can over-buffer past the
    footage actually needed. This would lead to large duplication of data which <b>yet again causes bandwidth issues</b>.
</p>
<p>
    The only reasonable method when I was building this seemed to be:
    <ul>
        <li>Slice up the video into sections.</li>
        <li>Have each section, once loaded, trigger the loading of a next section in a hidden video element.</li>
        <li>At the transition, swap the now loaded video in.</li>
        <li>Delete the old video.</li>
        <li>Repeat.</li>
    </ul>
    This had the benefit of only ever loading the footage collection once in worst-case. In average case it would
    load less because the vast majority of footage traversals would not use every clip, and thus they would be
    skipped (and not requested) altogether. This method had major implications for the actual editing process,
    but this seemed to be the simplest distribution of the video.
</p>
<h4>The Raw Footage Editing Process:</h4>
<p>
    This first task in editing the video was breaking down the raw footage into clips and loosely categorizing them.
    The editing program I used was <a href="https://www.adobe.com/products/premiere/campaign/pricing.html?sdid=KKQOM&mv=search&ef_id=CjwKCAjwh4ObBhAzEiwAHzZYU16ZI_pB2Ie77w12VZSlg8cEXYbTnzXWCRmittefcMjG6FXCOB1XThoCgOQQAvD_BwE:G:s&s_kwcid=AL!3085!3!383822034468!e!!g!!adobe%20premier!1712852043!83993219448&mv=search&gclid=CjwKCAjwh4ObBhAzEiwAHzZYU16ZI_pB2Ie77w12VZSlg8cEXYbTnzXWCRmittefcMjG6FXCOB1XThoCgOQQAvD_BwE" target="_parent">Adobe Premier</a>.
    Premier allows the <a href="https://nofilmschool.com/premiere-pro-tagging-workflow" target="_parent">extension of clip metadata to include tags</a>, which I used as a way to do more fine-grain categorizing.
</p>
<img src="images/premier_interface.png">
<p>
    The tagging process was not meant as a tool transition edits as much as it was a census of topics that came up through
    my grandmother's stories. The initial pass was just to break the footage down into logic chunks (which would ultimately
    be the chunks used for the video switching) and to help focus my editing on a second pass when creating transitions between
    the clips.
</p>
<h4>Proof of Concept:</h4>
<p>
    While doing the course edit and clip making, I tried making a demo of the harness that would orchestrate the video switching.
    I ultimately wanted the videos to be plain-jane MPEG4s so I could leverage the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video" target="_parent">html5 video api</a>
    instead of having to deal with some kind of library. This meant the elements would be handled by some harness driven by a configuration
    to specify the clips and their transitions. <i>Release</i> used a transpiler to generate a bootstrap function to generate the
    graph walk, but I wanted to fully separate code deployment from application state for <i>Verna Gray</i>. So I worked
    out a serviceable configuration language in JSON:
</p>
<pre>
    "clips": {
        "$some_name_for_the_clip": {
            "file": "$the_clips_actual_file_path.mp4",
            "transitions": [
                {
                    "name": "$a_name_for_the_transition_to_help_debugging",
                    "jump_from_timestamp": 290, // <- when to leave the current clip
                    "jump_to_clip": "$the_name_of_the_clip_to_go_to",
                    "jump_to_timestamp": 0 // <- What timestamp to jump into on the new clip
                }
            ]
        }
    ...
</pre>
<p>
    The initial harness used <code>SetInterval</code> to queue up the transitions for the videos. The basic idea is that
    when a user kicks off the initial video, the harness would randomly choose a walk through the configuration. It would
    then go step by step, keeping track of the time and set intervals for a function to run with predefined arguments so it
    would interact with the correct video clips. The time had to be kept during this setup because each successive transition
    needed to be offset by the length of the walk that lead to it. For example, if a clip was 7 seconds long but transitioned
    after a 30-second clip, its interval had to be set to 37 seconds instead of 7. You might be starting to see how this was
    a poor choice. I initially went this route because I used <code>SetInterval</code> in <i>Release</i> to manage the
    dyslexia effects. It was perfect there because none of the effects depended on the timing of any other, so they could just
    happen in isolation. The dependence of clips in <i>Verna Gray</i> made this a nightmare for debugging. This interval
    centric method also made it <i>so you couldn't pause the video</i>. The intervals didn't pause when the video did, so
    they would just keep firing away without warning.
</p>
<p>
    Ultimately I ended up switching to using <code>.ontimeupdate</code> instead. This allowed the videos to read
    from a manifest of transition and set up <b>just the next jump</b> and only transition once <b> the
    current videos timestamp matched the timestamp in the config</b>. No timing offsets, no issues pausing video, and
    a much easier time debugging. It also had the benefit of being much easier in optimizing when to get rid of videos
    after they played to save memory.
</p>
<p>
    I initially tested with a small set of demo clips, but after seeing it work, I paused developing it anymore until
    I had the interview footage in hand.
</p>
<h4>Marks The Spot:</h4>
<p>
    Once the initial clips were cut in Premier, I used "<a href="https://helpx.adobe.com/premiere-pro/using/markers.html" target="_parent">marks</a>"
    to notate the timestamps of when subjects had a good point the segue from. For example a natural pause in
    conversation just after finishing a point about Jack Silsby has a mark to say "we can jump from here to
    another clip about Jack." At this point I found the x2 playback option and things went pretty quickly.
</p>
    <img src="images/premier_marks.png">
<p>
    The reason I didn't mark the points of entry for the clips ("we can <i>start</i> talking about Jack here")
    is because the entrance might want to be different based on the end of the clip that jumps to it. Given
    that possible inconsistency, I decided to leave that "point of entrance" marking until later.
</p>
<p>
    I ended up exporting the markers on the clips to use with a custom script to generate a base config for the
    harness to just play through all the clips (IE: 1 would play in its entirety, transition to the beginning
    of clip 2, and so on). This gave us our base traversal.
</p>
<h4>Analog Editing (Part 1):</h4>
<p>
    Now I wish I could say I made some grand program for organizing all the transitions, but I didn't.
    This part, to me, really is the editing process for this project and I, having never done it at this
    size before, decided to not spend the time working on an interface for a process I had never done.
    Instead, I broke out a notebook and sketched the thing out:
</p>
<img src="images/structure.png">
<p>
    I've been calling this a "Linear Grid Chart" which doesn't make totally sense, but is the best I got right
    now. I sort of thought about it as a musical staff and the audience as some monophonic synth weaving around.
    The rules for traversal were different from a staff though:
<p>
<ol>
    <li>You can move right on your current line.</li>
    <li>You can move right or left to any line below your current position.</li>
    <li>You cannot move up to a prior line, even if you skipped over it prior.</li>
    <li>You cannot move left on your current line, even if you skipped over it prior</li>
</ol>
<p>
    The direction of the traversal over this Linear Grid Chart can best be described as
    "downwards and mostly left."
</p>
<h4>Why No Loops:</h4>
<p>
    The reason for this structure was to avoid loops. There are other ways, but this meant I have
    practically 0 chance of creating a loop unless I screwed up my own rule set. The reason I so
    doggedly wanted to avoid loops was because of what video of my grandmother repeating the same story
    over and over would imply in the meaning of the traversal. My grandmother is cogent, and sharp.
    A loop over stories would insinuate she has issues with memory or time, which isn't true. So
    the rules are to avoid a mistake of creating a loop all together.
</p>
<h4>Analog Editing (Part 2):</h4>
<p>
    With the Rules in mind, I drew out the connections:
</p>
<img src="images/transition_sheets.png">
<p>
Other than looking like little like a <a href="https://cageconcert.org/wp-content/uploads/2018/11/p.-30.jpg" target="_parent"> John Cage composition</a>,
the traces were fairly successful as giving me a map to append to the base configuration for the harness.
</p>
<p>
    With the clips in hand, I did a third pass through the footage to figure out the time stamp each
    transition point should jump into when moving to the new clip.
</p>
<h4>Hosting and Deploying the Videos:</h4>
 <p>
     I am a burnt out tech worker. I don't want to write CI/CD. I want to copy a file somewhere, have it run
     and not need to think about it burning my house down because I didn't update Express.js for a security patch
     or something.
 </p>
<p>
    The hope was to figure out how to host the site as a static webpage and let HTML5 tags to the lifting for the
    video streaming. After a quick look, <a href="https://www.digitalocean.com/" target="_parent"> Digital Ocean</a> ended up being
    the hosting platform I chose. Vultr and Linode has slightly smaller Storage options (remember I need to server
    27 gbs of video) and I literally cannot figure out how to estimate costs in AWS.
</p>
<p>
    For the actual webserver, I am using <a href="https://httpd.apache.org/" target="_parent"> Apache "<code>httpd</code>" Server </a>
    It is fast, easy to install, doesn't require <code>yarn</code> or <code>npm</code>, and is fine for static webpages
    (which the project technically falls under).
</p>
<p>
    That's it really. There is no js library. No reverse proxy. Nothing fancy.
</p>
<h4>Future Improvements:</h4>
<p>
    Ultimately there is an easier way to make videos like this: use a video player that can buffer in multiple
    places.
</p>
<p>
    I don't really know how to do something like that over the web, but it certainly can be done as a local app.
    I think trying to leverage unity for the web might be able to pull it off, given the control you have over their
    video player. But I really don't know yet. Getting the edit outside the Linear Grid Chart and instead think of
    transitions as skips on a chronological line would free up a lot of editing burden.
</p>
<p>
    I think once I settle on an editing process, building tools to auto compile a lot of this would be both easy
    and a great accelerator of getting this kind of work together.
</p>
<h4>Final Notes</h4>
<p>
    There are a lot of other kinds of stories to be told in some structure/harness like this.
    What about stories that loop? What about stories that let you chose which path to take?
    What is the transition lines are generated or randomized? What if we went full cage-ian and used
    the transition lines from one piece on another?
</p>
<p>
    This single version of the video project has roughly 1,286,384,503 different permutations. And as
    time goes on, and I add more to it: that will grow. I don't know when I tackle another video project
    like this, but there are plenty more experiments and avenues to once I do.
</p>

</body>
</html>